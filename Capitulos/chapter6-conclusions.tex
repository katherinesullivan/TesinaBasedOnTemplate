\chapter{Conclusiones}
~\label{cap:conclusions}
\vspace{-1cm}

La motivación de este trabajo fue estudiar en profundidad los juegos
estocásticos politópicos (PSG) con objetivos de Rabin, y ver qué preguntas de
investigación típicas del campo de estudio de juegos podríamos responder de
ellos. El principal aporte de este trabajo fue presentar una desrandomización
sistemática de los PSGs con objetivos de Rabin, introduciendo los \emph{juegos
	de adversario justo} como objeto central de estudio.

La contribuciones concretas pueden resumirse en los siguientes puntos clave:

\begin{enumerate}
	\item Definimos formalmente los juegos justos y mostramos cómo, dada la
	      interpretación de un PSG $\Gk$, se puede construir su desrandomización $\DGk$
	      como un juego determinista con suposiciones de \emph{justicia extrema} sobre
	      ciertas aristas salientes.
	\item Establecimos una correspondencia biunívoca entre caminos y estrategias en el
	      PSG y en su desrandomización, mediante las funciones \texttt{desrand} y
	      \texttt{rand} y demostramos que un estado $s$ es ganador en el PSG si y sólo si
	      es ganador en el juego justo correspondiente.
	\item A partir de esta equivalencia, se derivan dos consecuencias fundamentales:
	      \begin{itemize}
		      \item Es posible realizar la \emph{sintésis de estrategias ganadoras} para el PSG
		            mediante la construcción de estrategias sin memoria en $\DGk$ y su posterior
		            traducción de vuelta al PSG.
		      \item Aprovechando los algoritmos existentes para juegos justos con objetivos de
		            Rabin, en particular el método simbólico de Banerjee et al. \cite{Banerjee},
		            obtenemos un procedimiento efectivo con complejidad $O((n\,l)^2\,d!)$, donde
		            $n$ es el número de estados en el PSG, $l$ el máximo soporte de las acciones, y
		            $d$ el número de pares Rabin.
	      \end{itemize}
\end{enumerate}

Nuestra metodología ofrece una reducción natural del problema probabilístico a
un problema completamente determinista, permitiendo reutilizar herramientas
estándares para juegos de dos jugadores deterministas.

Así, respondemos satisfactoriamente a las dos preguntas centrales:
\textit{“quién gana”}, al caracterizar los estados ganadores con probabilidad 1
en un PSG mediante la construcción de $\DGk$, y \textit{“cómo se gana”}, al
proporcionar un esquema sistemático para sintetizar estrategias ganadoras a
través de la transformación entre estrategias en $\Gk$ y estrategias en $\DGk$.

Finalmente, la introducción de los juegos de adversario justo y la metodología
de desrandomización constituyen una contribución conceptual de carácter
general. Podrían ser aplicadas también más allá del marco de los PSG con
objetivos de Rabin a otros modelos estocásticos. Pero esto no es lo único que
se podría pensar a futuro como extensión de este trabajo.

% Durante el desarrollo de este trabajo se estudiaron diversos tipos de modelos matemáticos que permiten representar sistemas computacionales. El estudio de los mismos fue el catalizador necesario para poder responder las preguntas de investigación sobre nuestro modelo particular de interés: los juegos estocásticos politópicos 

\section{Trabajo Futuro}
~\label{cap:conclusions:sec:future}

Los resultados que pudimos lograr en el estudio de PSGs con objetivos de Rabin
se limitaron al contexto de análisis de lo que definimos como la pregunta
cualitativa en el capítulo~\ref{cap:objetivos}. Sin embargo, nuestra idea
hubiese sido también poder demostrar algo relacionado a la pregunta
cuantitativa. Reiterando brevemente, en el estudio de la pregunta cualitativa
es de nuestro interés saber si un estado es ganador con probabilidad uno,
mientras que en el caso de la pregunta cuantitativa nos interesamos por la
probabilidad máxima de ganar desde un estado. Para abordar la pregunta
cuantitativa se nos ocurrieron dos métodos.

En primer lugar, pensamos en intentar derivar un resultado como el segundo
propuesto por Chatterjee para juegos estocásticos en \cite{ComplexityRabin}:
mostrar que si una familia de estrategias es suficiente para el cálculo de
regiones ganadoras entonces también es suficiente para el cálculo de valores de
los estados. Según las pruebas realizadas en \cite{ComplexityRabin}, parece que
podría ser útil primero intentar probar el teorema fundamental de las
componentes finales para PMDPs en su caso general y no limitado a estrategias
de memoria finita (véase teorema~\ref{teoFundEC}), antes de adentrarse en
querer probar lo propuesto en este párrafo. En caso de tener éxito probando
esto, por lo que presentamos en esta tesina podríamos decir que para el cálculo
de valores de estados en un PSG con objetivos de Rabin bastará solo con buscar
entre las estrategias puras y sin memoria.

En segundo lugar, pensamos que se podría intentar probar algo al estilo del
primer teorema en \cite{Polytopal} y ver que el encontrar el valor en un estado
de un PSG para un objetivo de Rabin puede ser equivalente a buscar el valor de
un estado en la interpretación extrema del juego. Si bien no pudimos llegar a
una conclusión fuerte sobre si esto es posible en general, creemos que es
verdad que podemos transformar una estrategia determinista sin memoria en dos
estrategias extremas, randomizadas y sin memoria. Si pensamos en estrategias
extremas podemos pensar directamente en la resolución del valor la
interpretación extrema del juego, que es un juego estocástico no politópico.
Una tarea futura muy concreta podría bien ser ver si se puede formalizar esta
idea de transformación de estrategias MD en pares de estrategias MRX y luego
ver si para el cálculo del valor en el PSG podríamos limitar nuestra búsqueda a
las estrategias MD. En caso de poder hacer esto y valiéndonos de trabajo
existente en la literatura, podríamos dar algoritmos concretos para el cálculo
del valor de un estado en un PSG con objetivo de Rabin.

Sin importar cuál abordaje se tome, el estudio de la pregunta cuantitativa para
PSGs con objetivos de Rabin sería el próximo paso natural para dar y sería muy
interesante ver qué es lo que se puede lograr y qué nuevas puertas para la
modelización y verificación eso puede abrir.