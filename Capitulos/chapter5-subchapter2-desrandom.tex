\section{Juegos justos y desrandomización de un PSG}
\label{sec:prueba}

A fin de responder la pregunta cualitativa en el estudio de los juegos
estocásticos politópicos con objetivos de Rabin, presentaremos un tipo nuevo de
juegos deterministas: los juegos justos. Probaremos que el conjunto de vértices
ganadores con probabilidad 1 en un juego estocástico politópico con un objetivo
de Rabin es igual al conjunto de vértices ganadores de un juego justo
construido a partir del PSG.

Para eso primero presentaremos el concepto de juego justo y la construcción del
juego justo a partir del PSG. Luego, explicitaremos un poco más la relación
entre el PSG y el juego justo construido, al cual llamaremos su
desrandomización. Seguido de eso, expondremos la prueba formal de la igualdad
entre los conjuntos. Y, por último, mostraremos un algoritmo para el cálculo de
los estados ganadores y la sintésis de estrategias ganadoras para un PSG con un
objetivo de Rabin. % VER ESTO EN DEPENDENCIA DE LO QUE TERMINEMOS ESCRIBIENDO AL FINAL

\subsection*{Juegos de adversario justo}

Sea $G$ un juego de grafo de dos jugadores y sea $E^{l} \subseteq (V_\diam
	\times V) \cap E$ un conjunto dado de aristas que deben ser tomadas
infinitamente a menudo si el estado del que parten es visitado infinitamente a
menudo. Nombraremos $V^{l} := \mathrm{dom}(E^{l})$ al conjunto de vértices del
jugador $\diam$ que está en el dominio de $E^{l}$. Las aristas en $E^{l}$
representarán suposiciones de equidad sobre el jugador $\diam$: para cada
arista $(v, v') \in E^{l}$, si $v$ es visitado infinitamente a menudo en una
jugada, se espera que la arista $(v, v')$ sea elegida también infinitamente a
menudo por el jugador $\diam$. Es decir, si un vértice $v$ es visitado
infinitas veces, se espera también que toda arista en $E^l$ saliente de $v$ sea
tomada una cantidad infinita de veces.

Denotamos por $G^{l} = \langle G, E^{l} \rangle$ a un juego de adversario
justo, y extendemos nociones como jugadas, estrategias, condiciones ganadoras,
regiones ganadoras, etc. de juegos deterministas de manera natural. Una jugada
$\rho$ sobre $G^{l}$ se dice fuertemente justa si satisface la siguiente
fórmula en lógica temporal lineal (LTL):
\[
	\alpha := \bigwedge_{(v, v') \in E^{l}} \left( \siempevent v \rightarrow \siempevent (v \wedge \bigcirc v') \right).
\]
Dado $G^{l}$ y una condición de victoria $\varphi$, el jugador $\cuad$ gana el
juego de adversario justo sobre $G^{l}$ con respecto a la condición de victoria
$\varphi$ desde un vértice $v_0 \in V$ si gana el juego sobre $G^{l}$ para la
condición de victoria $\alpha \rightarrow \varphi$ desde $v_0$.

Hay dos observaciones interesantes para hacer sobre los juegos de adversario
justo:

Primero, las aristas en $E^l$ permiten descartar ciertas estrategias del
jugador $\diam$, facilitando que el jugador $\cuad$ gane en determinadas
situaciones. Por ejemplo, consideremos un grafo de juego (figura X, parte
superior) con dos vértices $p$ y $q$. El vértice $p$ pertenece al jugador
$\diam$ y el vértice $q$ al jugador $\cuad$. La arista $(p, q)$ es una arista
en $E^l$ (representada con línea discontinua). Supongamos que la especificación
para el jugador $\cuad$ es $\varphi = \siempevent q$. Si la arista $(p, q)$ no
estuviera en $E^l$, el jugador $\cuad$ no ganaría desde $p$, porque el jugador
$\diam$ podría mantener el juego atrapado en $p$ eligiéndose a sí mismo como
sucesor en cada turno. En contraste, el jugador $\cuad$ gana desde $p$ en el
juego adversarial justo, porque la suposición de equidad sobre la arista $(p,
	q)$ fuerza al jugador $\diam$ a elegir infinitamente a menudo la transición
hacia $q$.

Segundo, las suposiciones de equidad modeladas por aristas en $E^l$ restringen
las elecciones de estrategias del jugador $\diam$ menos que lo que
restringirían la suposición de que el jugador $\diam$ elige probabilísticamente
entre estas aristas. Consideremos, por ejemplo, un juego de adversario justo
con un único vértice del jugador $\diam$, $p$ con dos aristas en $E^l$
salientes hacia los estados $q$ y $q'$, como se muestra en la Figura 1 (parte
inferior). Si el jugador $\diam$ elige aleatoriamente entre las aristas $(p,
	q)$ y $(p, q')$, toda secuencia finita de visitas a los estados $q$ y $q'$
ocurrirá infinitamente a menudo con probabilidad uno. Esto no es cierto en el
juego de adversario justo. Aquí el jugador $\diam$ puede elegir una secuencia
particular de visitas a $q$ y $q'$ (por ejemplo, simplemente $qq'qq'qq'\dots$),
siempre que ambos sean visitados infinitamente a menudo.

\begin{figure}[ht]
	\centering
	\begin{tikzpicture}[>=Stealth, node distance=3.5cm, font=\scriptsize]
		% Definición de estilos para los nodos
		\tikzset{
			state/.style={draw, circle, minimum size=1.2cm, font=\normalsize},
			square state/.style={draw, rectangle, minimum size=1.2cm, font=\normalsize},
			diamond state/.style={draw, diamond, aspect=1.5, minimum size=1.5cm,font=\normalsize}
		}

		% --- Figura superior ---.
		\node[diamond state] (p1) at (0,0) {$p$};
		\node[square state] (q1) [right of=p1] {$q$};

		% Transiciones:
		\draw[->] (p1) edge[loop left] (p1);
		\draw[->, dashed] (p1) to[bend left=20] (q1);
		\draw[->] (q1) edge[bend left=20] (p1);

		% --- Figura inferior ---
		\node[diamond state] (p2) at (0,-3.5) {$p$};
		\node[square state] (q2) [above right=0.5cm and 1cm of p2] {$q$};
		\node[square state] (q2p) [below right=0.5cm and 1cm of p2]  {$q'$};

		% Transiciones:
		\draw[->, dashed] (p2) to[left] (q2);
		\draw[->, dashed] (p2) edge[left] (q2p);
		\draw[->] (q2) edge[bend left=20] (p2);
		\draw[->] (q2p) edge[bend left=20] (p2);

	\end{tikzpicture}
	\caption{Dos juegos de adversario justo.}
	\label{fig:juego-justo}
\end{figure}

\subsection*{Desrandomización de PSGs}

Dada la interpretación de un juego estocástico politópico $\Gk = (\St,
	(\St_\cuad, \St_\diam), \Act, \theta)$, se define la \textit{desrandomización
	de} $\Gk$, $\DGk := (( V, V_\cuad, V_\diam, E ), E^l )$, como el (vamos con
esta traducción?) juego de grafo de 2 jugadores extremadamente equitativo con:

\begin{alignat*}{2}
	&\tilde V &&= \newV \\
	&V &&= \St \cup \tilde V \\
	&V_\cuad &&= \St_\cuad \\
	&V_\diam &&= \St_\diam \cup \tilde V \\
	&E &&= \{(s, v_{V}) : V \in V_s\} \\
	&E^l &&= \{(v_{V}, s') : s' \in V\}
\end{alignat*}

y para el cual se cumple la siguiente condición de equidad: $$ \varphi^l :=
	\bigwedge_{(v_{V'},s') \in E^l} (\siempevent v_{V'} \rightarrow \siempevent
	(v_{V'} \wedge \bigcirc s' )) $$

Esta misma condición de equidad se puede expresar como

\begin{center}
	$ \varphi^l : = \bigwedge_{v_V \in \tilde V} \varphi^V $, donde

	$ \varphi^V := \bigwedge_{s' \in V} (\siempevent v_{V'} \rightarrow \siempevent (v_{V'} \wedge \bigcirc s' ))$
\end{center}

\subsection*{Relación entre un PSG y su desrandomización}

Nos será útil pensar en transformaciones entre los distintos juegos para la
prueba que tenemos más adelante, así que veremos algunas definiciones. Antes,
fijemos la interpretación de un juego estocástico politópico $\Gk$ y su
desrandomización $\DGk$.

\textbf{Condición de equidad en el juego estocástico politópico}

Podemos expresar fácilmente la condición de equidad en el juego estocástico
politópico de la siguiente forma:

\begin{center}
	$
		\hat \varphi^l := \bigwedge_{\alpha \in \Act} \hat \varphi^{\supp(\alpha)}
	$, con

	$
		\hat \varphi^{\supp(\alpha)} := \bigwedge_{s' \in \supp(\alpha)} (\siempevent \alpha \rightarrow \siempevent (\alpha \wedge \bigcirc s' ))
	$
\end{center}

\textbf{Transformación de caminos}

Dado un camino $\omega = (s_0, \alpha_0, s_1, \alpha_1, \dots)$ en $\Gk$,
podemos obtener un único camino en $\DGk$ al que llamaremos $\derand(\omega)$ y
tendrá la siguiente forma: $$\derand(\omega) = (s_0, v_{\supp(\alpha_0)}, s_1,
	v_{\supp(\alpha_1), \dots})$$ Por otro lado, si tenemos un camino $\rho = (s_0,
	v_{V_0}, s_1, v_{V_1}, \dots)$ en $\DGk$, existen varios caminos en $\Gk$ que
se corresponderían con él. Llamaremos a este conjunto de caminos $\rand(\rho)$.
Es decir, $$\rand(\rho) = \{(s_0, \alpha_0, s_1, \alpha_1, \dots) \in
	\Omega_{\Gk,s} \mid \forall i \geq 0, \ \supp(\alpha_i) = V_i\}$$

Estas definiciones también se extienden a prefijos finitos de caminos de manera
natural.

\textbf{Randomización de estrategias}

Supongamos que tenemos una estrategia $\sigma_i$ en $\DGk$ y queremos construir
una estrategia $\pi_i$ en $\Gk$ que tenga un comportamiento similar. $\sigma_i$
está definida para todos los prefijos finitos de caminos $\rho$ en $\DGk$ y
nuestra idea es definir $\pi_i$ para todos los prefijos finitos de camino
$\omega$ en $\Gk$. La idea, entonces, será definir $\pi_i$ de igual manera para
todos los elementos del conjunto $\rand(\rho)$.

Solo nos va a interesar ver cómo $\sigma_i$ se comporta en los prefijos finitos
de caminos $\rho$ que terminen en un estado $s \in \St$ \footnote{Desde los
	prefijos finitos de caminos donde el último elemento es un vértice $v_V$, las
	decisiones son tomadas por el jugador $\diam$ en $\DGk$, pero solo reflejan lo
	que sería la decisión probabilística en $\Gk$.}. Para cada uno de estos $\rho$,
tenemos que $\sigma_i(\rho) = v_{\widehat{V}}$ para algún $v_V$. Lo que haremos
para la construcción de $\pi_i$ es para cada $\omega \in \derand(\rho)$ definir
$\pi_i(\omega)(\hat\alpha) = 1$ para algún $\hat\alpha$ particular tal que
$\supp(\hat\alpha) = \widehat{V}$.

Llamaremos a esta nueva estrategia $\pi_i$ obtenida a partir de $\sigma_i$,
$\rand(\sigma_i)$.

\begin{center}
	$\sigma_i(s_0, v_{V_0}, \dots, s_k) = v_{V_k} \implies \rand(\sigma_i)(s_0, \alpha_0, \dots, s_k)(\alpha_k) = 1$ donde \\ $\forall i \ \supp(\alpha_i) = V_i$.
	\captionof{figure}{Una forma de ver la randomización de estrategias en $\DGk$}
\end{center}
% \begin{figure}[ht]
% 	\centering
% 	\begin{equation*}
% 		\sigma_i(s_0, v_{V_0}, \dots, s_k) = v_{V_k} \implies
% 		\rand(\sigma_i)(s_0, \alpha_0, \dots, s_k)(\alpha_k) = 1
% 	\end{equation*}
% 	\caption{Una forma de ver la randomización de estrategias}
% \end{figure}

\textbf{Desrandomización de estrategias}

Supongamos ahora que tenemos una estrategia $\pi_i$ en $\Gk$ y queremos
construir una estrategia $\sigma_i$ en $\DGk$ que tenga un comportamiento
similar.

Para cada prefijo finito de camino $\rho$ debemos definir qué vértice será el
que elija $\sigma_i(\rho)$. La idea será que elegiremos un vértice $v_V$ que se
corresponde al soporte de una acción a la que $\pi_i(\omega)$ (siendo $\omega$
tal que $\derand(\omega) = \rho$) le asigne una probabilidad positiva.

Como existen varios prefijos de camino que podrían cumplir con la condición de
$\omega$, la definición de $\derand(\pi_i)$ dependerá de la elección de un
prefijo de camino $\omega$ para cada prefijo de camino $\rho$ tal que
$\derand(\omega) = \rho$.

Además, como cada acción le puede dar probabilidad positiva a varias acciones
con distintos soportes, la definición de $\derand(\pi_i)$ también dependerá de
la elección de una acción a la que $\pi_i(\omega)$ le asigne una probabilidad
positiva (por cada $\omega$ seleccionado en el paso anterior).

\begin{boxgris}[¿Cómo se podrían tomar esas elecciones?]{}
	Suponiendo que tenemos una estrategia $\pi_i$ en $\Gk$, es probable que a su vez tengamos caminos $\omega'_1, \omega'_2, \dots$ en $\Gk$ específicos en que estemos interesados que $\sigma_i$ replique. En ese caso, una manera de tomar las decisiones antes planteadas es usando los prefijos finitos de los distintos $\omega'_k$ para las decisiones de $\sigma_i$. Esto sería: si tenemos un prefijo de camino $\hat \omega = (s_1, \alpha_1, \dots, s_m, \alpha_m)$ (que respeta $\pi_i$), entonces haremos que para $\hat \rho = (s_1, v_{\supp(\alpha_1)}, \dots, s_m)$, $\sigma_i(\hat \rho) = v_{\supp(\alpha_m)}$.
\end{boxgris}

Con estas decisiones tomadas, podemos definir como se comportará $\sigma_i$
para cada prefijo de camino que termina en un estado $s \in \St$.

Ahora bien, para el caso de $\sigma_\diam$ también hay que definir cómo se
comporta la estrategia en los caminos que terminan en los vértices de la forma
$v_V$. Es decir, debemos elegir qué estado $s_{k+1}$ será el que cumpla
$\sigma_\diam(s_0, v_{V_0}, \dots, s_k, v_{V_k}) = s_{k+1}$ para cada $k$. En
este caso, lo que nos debemos asegurar es que se cumpla la condición de
equidad.

% Se podría pensar como tener esto aparte o enmarcado en una box. Se podría agregar otra box con lo que sería medio la precontinuacion del punto 2
\begin{boxgris}[¿Cómo asegurar la condición de equidad?]{}
	Presentamos dos maneras fáciles con las cuales se podría asegurar esto, pero
	podrían existir infinidades de ellas:
	\begin{enumerate}
		\item como cada $V_k$ es finito, podemos numerar cada $s^{V_k} \in V_k$ de manera
		      $s_0^{V_k}, s_1^{V_k}, \dots$. Esto nos permite seleccionar el próximo estado
		      en base a la cantidad de veces que se visitó $v_{V_k}$. Si $n$ fueron las veces
		      que se visitó $v_{V_k}$ en el prefijo finito de camino $\rho '$, entonces
		      podemos definir $\sigma_\diam(\rho ' v_{V_k}) = s_n^{V_k}$.
		\item si tenemos un camino $\hat \omega$ válido que respeta la estrategia
		      $\pi_\diam$, y a partir de los prefijos de este $\hat \omega$ es que estamos
		      definiendo las elecciones de prefijos y acciones de $\sigma_\diam$, podemos
		      también usar este $\hat \omega$ para las decisiones desde los estados
		      $v_{V_k}$, eligiendo como próximo vértice $s_{k+1}$ al que se eligió
		      probabilísticamente en $\hat \omega$.
	\end{enumerate}
\end{boxgris}

Con estas decisiones ya tomadas resulta la construcción de la $\sigma_i$ que
queríamos, a la cual llamaremos $\derand(\pi_i)$.

\textbf{Respetar una estrategia}

Al hablar de caminos específicos es natural pensar que estos fueron producto de
una partida en la que los jugadores siguieron determinadas estrategias. Para la
prueba que plantearemos a continuación querremos formalizar esta relación entre
caminos y las estrategias que se siguieron en ellos y lo haremos a través de la
idea de que un camino ``respeta" determinadas estrategias.

Sea $\omega = (s_0, \alpha_0, s_1, \alpha_1, \dots)$ un camino en un juego
estocástico poliópico y sean $\picuad$ y $\pidiam$ dos estrategias en el mismo
juego. Decimos que $\omega$ respeta las estrategias $\picuad$ y $\pidiam$ si
$\forall i \geq 0$ vale
\begin{align*}
	&\bigl( s_i \in \St_\cuad \wedge \picuad(s_0, \alpha_0, \dots, s_i)(\alpha_i) > 0 \wedge s_{i+1} \in \supp(\alpha_i) \bigr) \bigvee \\
	&\left(s_i \in \St_\diam \wedge \pidiam(s_0, \alpha_0, \dots, s_i)(\alpha_i) > 0 \wedge
	s_{i+1} \in \supp(\alpha_i) \right)
\end{align*}
% \begin{align*}
% 	&\bigl( s_i \in \St_\cuad \wedge \picuad(\hat
% 	\omega_i)(\alpha_i) > 0 \wedge s_{i+1} \in \supp(\alpha_i) \bigr) \bigvee \\
% 	&\left(s_i \in \St_\diam \wedge \pidiam(\hat \omega_i)(\alpha_i) > 0 \wedge
% 	s_{i+1} \in \supp(\alpha_i) \right)
% \end{align*}

Sea $\rho = (s_0, v_{V_0}, s_1, v_{V_1}, \dots)$ un camino en la
desrandomización de un juego estocástico politópico y sean $\sigma_\cuad$ y
$\sigma_\diam$ dos estrategias en el mismo juego. Decimos que $\rho$ respeta
las estrategias $\sigma_\cuad$ y $\sigma_\diam$ si $\forall i \geq 0$ vale

\begin{align*}
	\sigma_\diam&(s_0, v_{V_0}, \dots, s_i, v_{V_i})=s_{i+1} \bigwedge \\
	&\bigl( \left( s_i \in \St_\cuad \wedge \sigma_\cuad(s_0, v_{V_0}, \dots, s_i)=v_{V_i} \right) \bigvee \\
	&\left( s_i \in \St_\diam \wedge \sigma_\diam(s_0, v_{V_0}, \dots, s_i)=v_{V_i} \right) \bigr)
\end{align*}
%$ \sigma_\diam(\hat \rho_{v_{V_i}})=s_{i+1} \bigwedge \left( \left( s_i \in \St_\cuad \wedge \sigma_\cuad(\hat \rho_{s_i})=v_{V_i} \right) \bigvee \left( s_i \in \St_\diam \wedge \sigma_\diam(\hat \rho_{s_i})=v_{V_i} \right) \right)$

\section{Prueba de igualdad sobre los conjuntos ganadores}

\begin{theorem}
	\label{teocuali}
	Sea $\Gk = (\St, (\St_\cuad, \St_\diam), \Act, \theta)$ la interpretación de un juego estocástico politópico, $R = \{(E_1, F_1), \dots, (E_d, F_d)\}$ una condición de Rabin sobre $\St$, con su especificación LTL $\varphi$,

	$$
		\varphi := \bigvee_{j \in [1, k]} \left( \eventsiemp \overline{E_j} \wedge \eventsiemp F_j \right)
	$$

	y sea $\DGk$ su desrandomización.

	Sea $\W \subseteq \St$ el conjunto de todos los estados desde los cuales el
	jugador $\cuad$ gana en $\DGk$ y sea $\W^{as}$ el conjunto de vértices desde
	los cuales el jugador $\cuad$ gana con probabilidad 1 en $\Gk$. Entonces, $\W =
		\W^{as}$.

	Es más, a partir de una estrategia ganadora en $\DGk$ se puede construir
	fácilmente una estrategia ganadora en $\Gk$, y viceversa.
\end{theorem}

\begin{proof}
	Probaremos la doble contención:

	\textbf{Primera contención: } $\W \subseteq \W^{as}$

	Sea $s \in \W$. Entonces, sabemos que existe al menos una estrategia del
	jugador $\cuad$ ganadora desde $s$ en $\DGk$. Llamemos a esta
	$\sigma_\cuad^{*}$.

	Queremos ver que $s \in \W^{as}$, lo que requiere ver que existe una estrategia
	$\picuadGk$ tal que:
	\begin{equation}
		\label{pisirve}
		\inf_{\pidiam \in \Pidiam} \Prob_{\Gk,s}^{\picuadGk, \pidiam}(\varphi) = 1
	\end{equation}

	Proponemos $\picuadGk = \rand(\sigma_\cuad^*)$ y veremos que vale \ref{pisirve}
	por reducción al absurdo.

	Supongamos que no vale \ref{pisirve}, es decir,
	\begin{equation}
		\inf_{\pidiam \in \Pidiam} \Prob_{\Gk, s}^{\picuadGk, \pidiam} (\varphi) < 1.
	\end{equation}

	Esto significa que existe una estrategia $\pidiam^*$ que hace que $\Prob_{\Gk,
			s}^{\picuadGk, \pidiam} (\varphi) < 1$. A su vez, esto significa que existe un
	camino $\omega^*$ que empieza desde $s$, respeta las estrategias $\picuadGk$ y
	$\pidiam^*$, pero no cumple $\varphi$.

	Pensemos, entonces, en $\sigma_\diam^*$ una desrandomización válida de
	$\pidiam^*$ que sigue las elecciones de acciones que toman los prefijos de
	$\omega^*$.

	Luego, $\rho^* = \derand(\omega^*)$ respeta las estrategias $\sigma_\cuad^*$ y
	$\sigma_\diam^*$. Como $\rho^* \cap \St = \omega^* \cap \St$ y $\omega^*$ no
	cumple $\varphi$, $\rho^*$ no cumple $\varphi$. Es decir, existe un camino que
	empieza desde $s$, respeta $\sigma_\cuad^*$, pero no es ganador para $\varphi$.
	Esto contradice que la estrategia $\sigma_\cuad^*$ sea ganadora desde $s$.

	Llegamos a esta contradicción por suponer que no vale \ref{pisirve}. Entonces
	la ecuación sí vale y, consecuentemente, tenemos que $s \in \W^{as}$, como
	queríamos probar.
	% -------------------------------------------------------------------------------------------------------------------------------------------------

	\textbf{Segunda contención: } $\W^{as} \subseteq \W$

	Sea $s \in \W^{as}$, veamos que $s \in \W$.

	Como $s \in \W^{as}$, entonces existe $\picuad^*$ en $\Gk$ tal que
	$\inf_{\pidiam \in \Pidiam}\Prob_{\Gk,s}^{\picuad^*, \pidiam}(\varphi) = 1$.

	Lo que queremos ver para probar que $s \in \W$ es que existe una estrategia
	$\sigma_\cuad^*$ tal que $\cuad$ gana con ella desde $s$ en $\DGk$.

	Definimos $\sigma_\cuad^* = \derand(\picuad^*)$

	Entonces ahora queremos ver que $\sigma_\cuad^*$ es ganadora en $\DGk$ desde
	$s$.

	Una manera de ver esto es probar que para un camino cualquiera $\rho$ generado
	por $\sigma_\cuad^*$ y una estrategia válida $\sigma_\diam$ arbitraria en
	$\DGk$, $\Inf(\rho)_C = \Inf(\rho) \cap \St$ cumple con la especificación
	$\varphi$. Es decir, que vale la siguiente fórmula:

	\begin{equation}
		\label{varphi}
		\varphi' := \bigvee_{j = 1}^{k} \left((\Inf(\rho)_C \cap R_j = \emptyset) \wedge (\Inf(\rho)_C \cap G_j \neq \emptyset)  \right)
	\end{equation}

	Como $\picuad^*$ es una estrategia ganadora frente a cualquier estrategia
	$\pidiam$, siempre se cumple la condición de Rabin con probabilidad 1 en el
	PMDP $\M'$ que se forma al fijar la estrategia $\picuad^*$ en $\Gk$. Por
	teorema~\ref{adaptB30}, entonces vale que para cada componente final $(C,D)$
	alcanzable desde $s$ en el PMDP $\M^*$ vale que existe algún $j \in [1,d]$ tal
	que $C \cap E_j = \emptyset$ y $C \cap F_j \neq \emptyset$.

	Si denotamos como $\Inf(\rho)_D$ a la función que le asocia a cada $s_i$ en
	$\Inf(\rho)_C$ el conjunto formado solo por el $V_i$ correspondiente al vértice
	$v_{V_i}$ en $\rho$, esto que presentamos anteriormente quiere decir que si
	podemos probar que $(\Inf(\rho)_C, \Inf(\rho)_D)$ es una componente final
	alcanzable desde $s$ en el PMDP $\M^*$, entonces vale la ecuación~\ref{varphi}.

	% probar que es subPMDP no hace falta pq es solo una cuestion de tipado

	Veamos entonces primero que $(\Inf(\rho)_C, \Inf(\rho)_D)$ cumple las dos
	condiciones para ser componente final en $\M^*$:

	% Si podemos probar que $\Inf(\rho)'$ es un sub-PMDP alcanzable en el PMDP que se
	% forma al fijar la estrategia de memoria finita $\picuad^*$ en $\Gk$, por el
	% teorema \ref{adaptB30} podemos ver que vale la ecuación \ref{varphi}.

	% Primero, podemos ver que $\inft(\rho)$ \hl{(entendiendo los vértices de la
	% 	forma $v_V$ como el conjunto resultado $V$)} es una componente final en el
	% polytopal markov decision process que se forma al fijar la estrategia
	% $\picuad^*$ en $\Gk$, llamémoslo $(C,D)$, viendo que cumple las dos
	% propiedades:

	\begin{itemize}
		\item Para cada $V^i$ que aparece como subíndice de vértices \textit{especiales} en
		      $\Inf(\rho)$, vale que $V^i \subseteq C$. En el caso de que existiese algún
		      $s_x \in V^i$ tal que $s_x \notin C$, se estaría contradiciendo que $\pidiam$
		      sea una estrategia válida en $\DGk$, puesto que visitaría infinitas veces
		      $v_{V^i}$ y solo finitas veces $s_x$, uno de sus sucesores.
		\item El grafo dirigido inducido por $\Inf(\rho)$ es fuertemente conexo. Si fuese de
		      otra manera habría dos vértices $u, v \in \Inf(\rho)$ tales que $v$ no sería
		      alcanzable desde $u$, contradiciendo así que $u$ y $v$ son visitados infinitas
		      veces por $\sigma$.
	\end{itemize}

	Luego, podemos ver que $\Inf(\rho)_C$ es alcanzable en $\Gk$ viendo que existe
	una estrategia $\pidiam^*$ en $\Gk$ que lo posibilita.

	Definamos $\pidiam^* = \rand(\sigma_\diam)$.

	Esta estrategia permite llegar con probabilidad positiva a $\Inf(\rho)_C$,
	puesto que tanto $\pidiam^*$ como $\picuad^*$ les dan probabilidad positiva a
	los mismos vértices en $\St$ que $\sigma_\diam$ asegura visitar infinitamente.

	Con lo cual hemos probado que vale l ecuación~\ref{varphi} y, por lo tanto, que
	$\sigma_\cuad*$ es ganadora en $\DGk$ desde $s$, con lo que hemos probado que
	$s \in \W$.

\end{proof}

\section{Implicancias algorítmicas de la prueba}

\subsection*{Complejidad del cálculo de estados ganadores en un PSG con objetivo de Rabin}

Haber podido probar esta igualdad nos permite calcular el conjunto de estados
casi seguramente ganadores para $\cuad$ en $\Gk$ mediante el algoritmo que se
propone en \cite{Banerjee} para calcular el conjunto de vértices ganadores en
un juego de adversario justo $G$ con un objetivo de Rabin $R$.

Este algoritmo tiene una complejidad de $O(n^2 d!)$ donde $n$ es la cantidad de
vértices en $G$ y $d$ la cantidad de pares en $R$.

Esto quiere decir que podemos calcular el conjunto de estados casi seguramente
ganadores para $\cuad$ en un PSG $\K$ con un objetivo de Rabin $R$ con una
complejidad de $O((n l)^2 d! )$ donde $n$ es la cantidad de estados en $\K$,
$d$ es la cantidad de pares en $R$ y $l = \max \{\abs{V_s} \mid s \in \St \}$
es la cantidad máxima de conjuntos soporte para las acciones que puede haber
desde un estado $s$ en $\K$.

\subsection*{Sintésis de estrategias ganadoras en un PSG con objetivo de Rabin}

El cálculo de desde qué estados gana el jugador $\cuad$ responde parcialmente a
la pregunta de ``¿quién gana?'', pero resulta no de menor importancia el
plantearse ``¿cómo se gana?''. Esta pregunta abarca tanto con qué clase de
estrategias se puede ganar como también podría enfocarse en describir paso a
paso cómo se deberían ver esas estrategias y se asocia a lo que es conocido
como el problema de \textit{sintésis de estrategias}, remarcado como de interés
en la literatura. En cierto punto, con lo demostrado, también respondemos
parcialmente a esta pregunta por lo siguiente.

El algoritmo simbólico planteado en la subsección anterior y propuesto en
\cite{Banerjee} permite extraer una estrategia sin memoria ganadora para el
jugador $\cuad$ en el juego justo, por lo que tendríamos así una estrategia sin
memoria ganadora en la desrandomización de un juego estocástico politópico con
objetivo de Rabin. Como nuestra prueba nos indica cómo, a partir de una
estrategia en la desrandomización, obtener una estrategia en el juego original,
con esto tenemos la manera de sintetizar una estrategia ganadora en un PSG con
objetivo de Rabin y estamos respondiendo, en cierta manera, a la pregunta de
``¿cómo se gana?''.

% El desarrollo de esta prueba en cierto punto nos permitió abordar la pregunta
% que planteamos como de nuestro interés en el capítulo~\ref{cap:objetivos} sobre
% ``¿quién gana?'' desde un estado. Ahora sería interesante poder abordar la
% pregunta de ``¿cómo se gana?''. Esta preguta se suele asociar a lo que es
% conocido como el problema de sintésis de estrategias. -> esto no es quite like
% that pq no hay aca una verdadera sintesis de estrategias sino que hay algoritmo
% para el calculo de esos estados en el juego desrandomizado. se puede hablar un
% poco de sintesis de estrategia al ver que se crean estrategias md a partir de
% estrategias md

% El algortimo de banerjee dice que se puede extraer una estrategia MD desde él, hay que explicarlo para poder tener esta sección